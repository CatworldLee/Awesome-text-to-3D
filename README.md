# Awesome-text-to-3D


* [Zero-shot text-guided object generation with dream fields](https://openaccess.thecvf.com/content/CVPR2022/papers/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.pdf)
* [DREAMFUSION: TEXT-TO-3D USING 2D DIFFUSION](https://arxiv.org/pdf/2209.14988.pdf)
* [Magic3D: High-Resolution Text-to-3D Content Creation](https://arxiv.org/pdf/2211.10440.pdf)
* [TextDeformer: Geometry Manipulation using Text Guidance](https://arxiv.org/pdf/2304.13348)
* [TextMesh: Generation of Realistic 3D Meshes From Text Prompts](https://arxiv.org/pdf/2304.12439)
* [DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model](https://arxiv.org/pdf/2304.02827.pdf)
* [DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models](https://arxiv.org/pdf/2304.00916.pdf)
* [DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance](https://arxiv.org/pdf/2304.03117)
* [AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control](https://arxiv.org/pdf/2303.17606)
* [X-Mesh: Towards Fast and Accurate Text-driven 3D Stylization via Dynamic Textual Guidance](https://arxiv.org/pdf/2303.15764)
* [Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion](https://arxiv.org/pdf/2304.00916.pdf)
* [Texture: Text-guided texturing of 3d shapes](https://arxiv.org/pdf/2302.01721)
* [Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation](https://arxiv.org/pdf/2303.13873)
* [Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation~\cite{hong2023debiasing}](https://arxiv.org/pdf/2303.15413)
* [CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout~\cite{lin2023componerf}](https://arxiv.org/pdf/2303.13843)
* [Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes~\cite{cohen2023set}](https://arxiv.org/pdf/2303.13450)
* [Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions~\cite{haque2023instruct}](https://arxiv.org/pdf/2303.12789.pdf?trk=public_post_comment-text)
* [SceneScape: Text-Driven Consistent Scene Generation~\cite{fridman2023scenescape}](https://arxiv.org/pdf/2303.10735)
* [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models~\cite{hollein2023text2room}](https://arxiv.org/pdf/2303.11989)
* [3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion~\cite{li20233d}](https://arxiv.org/pdf/2303.12218.pdf)
* [Compositional 3D Scene Generation using Locally Conditioned Diffusion~\cite{po2023compositional}](https://arxiv.org/pdf/2303.12218.pdf)
* [Text2Tex: Text-driven Texture Synthesis via Diffusion Models~\cite{chen2023text2tex}](https://arxiv.org/pdf/2303.11396)
* [SKED: Sketch-guided Text-based 3D Editing~\cite{mikaeili2023sked}](https://arxiv.org/pdf/2303.10735)
* [Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation~\cite{seo2023let}](https://arxiv.org/pdf/2303.07937)
* [Zero3D: Semantic-Driven Multi-Category 3D Shape Generation~\cite{han2023zero3d}](https://arxiv.org/pdf/2301.13591)
* [Text-to-4d dynamic scene generation~\cite{singer2023text}](https://arxiv.org/pdf/2301.11280.pdf?trk=public_post_comment-text)
* [Clip-mesh: Generating textured meshes from text using pretrained image-text models~\cite{mohammad2022clip}](https://dl.acm.org/doi/fullHtml/10.1145/3550469.3555392)
* [Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures~\cite{metzer2022latent}](https://arxiv.org/pdf/2211.07600.pdf)
* [Text2mesh: Text-driven neural stylization for meshes~\cite{michel2022text2mesh}](http://openaccess.thecvf.com/content/CVPR2022/papers/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.pdf)
