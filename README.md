# Awesome-text-to-3D

* [Zero-shot text-guided object generation with dream fields](https://openaccess.thecvf.com/content/CVPR2022/papers/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.pdf)
* [DREAMFUSION: TEXT-TO-3D USING 2D DIFFUSION](https://arxiv.org/pdf/2209.14988.pdf)
* [Magic3D: High-Resolution Text-to-3D Content Creation](https://arxiv.org/pdf/2211.10440.pdf)
* [TextDeformer: Geometry Manipulation using Text Guidance](https://arxiv.org/pdf/2304.13348)
* [TextMesh: Generation of Realistic 3D Meshes From Text Prompts](https://arxiv.org/pdf/2304.12439)
* [DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model](https://arxiv.org/pdf/2304.02827.pdf)
* [DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models](https://arxiv.org/pdf/2304.00916.pdf)
* [DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance](https://arxiv.org/pdf/2304.03117)
* [AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control](https://arxiv.org/pdf/2303.17606)
* [X-Mesh: Towards Fast and Accurate Text-driven 3D Stylization via Dynamic Textual Guidance](https://arxiv.org/pdf/2303.15764)
* [Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion](https://arxiv.org/pdf/2304.00916.pdf)
* [Texture: Text-guided texturing of 3d shapes](https://arxiv.org/pdf/2302.01721)
* [Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation](https://arxiv.org/pdf/2303.13873)
* [Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation](https://arxiv.org/pdf/2303.15413)
* [CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout](https://arxiv.org/pdf/2303.13843)
* [Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes](https://arxiv.org/pdf/2303.13450)
* [Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions](https://arxiv.org/pdf/2303.12789.pdf?trk=public_post_comment-text)
* [SceneScape: Text-Driven Consistent Scene Generation](https://arxiv.org/pdf/2303.10735)
* [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://arxiv.org/pdf/2303.11989)
* [3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion](https://arxiv.org/pdf/2303.12218.pdf)
* [Compositional 3D Scene Generation using Locally Conditioned Diffusion](https://arxiv.org/pdf/2303.12218.pdf)
* [Text2Tex: Text-driven Texture Synthesis via Diffusion Models](https://arxiv.org/pdf/2303.11396)
* [SKED: Sketch-guided Text-based 3D Editing](https://arxiv.org/pdf/2303.10735)
* [Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation](https://arxiv.org/pdf/2303.07937)
* [Zero3D: Semantic-Driven Multi-Category 3D Shape Generation](https://arxiv.org/pdf/2301.13591)
* [Text-to-4d dynamic scene generation](https://arxiv.org/pdf/2301.11280.pdf?trk=public_post_comment-text)
* [Clip-mesh: Generating textured meshes from text using pretrained image-text models](https://dl.acm.org/doi/fullHtml/10.1145/3550469.3555392)
* [Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures](https://arxiv.org/pdf/2211.07600.pdf)
* [Text2mesh: Text-driven neural stylization for meshes](http://openaccess.thecvf.com/content/CVPR2022/papers/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.pdf)
* [Tango: Text-driven photorealistic and robust 3d stylization via lighting decomposition](https://arxiv.org/pdf/2210.11277)

## text-to-avatar
* [DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models](https://arxiv.org/pdf/2304.00916.pdf)
* [DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance](https://arxiv.org/pdf/2304.03117)
* [AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control](https://arxiv.org/pdf/2303.17606)

## text-to-texture
* [Texture: Text-guided texturing of 3d shapes~\cite{richardson2023texture}](https://arxiv.org/pdf/2302.01721)
* [Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation](https://arxiv.org/pdf/2303.13873)
* [Tango: Text-driven photorealistic and robust 3d stylization via lighting decomposition](https://arxiv.org/pdf/2210.11277)
* [Text2Tex: Text-driven Texture Synthesis via Diffusion Models](https://arxiv.org/pdf/2303.11396)

## text-to-scene
* [Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes](https://arxiv.org/pdf/2303.13450)
* [SceneScape: Text-Driven Consistent Scene Generation](https://arxiv.org/pdf/2303.10735)
* [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://arxiv.org/pdf/2303.11989)
* [Text-to-4d dynamic scene generation](https://arxiv.org/pdf/2301.11280.pdf?trk=public_post_comment-text)
* [Compositional 3D Scene Generation using Locally Conditioned Diffusion](https://arxiv.org/pdf/2303.12218.pdf)

## text-guided shape tranformation

* [Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion](https://arxiv.org/pdf/2304.00916.pdf)
* [Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions](https://arxiv.org/pdf/2303.12789.pdf?trk=public_post_comment-text)
* [SKED: Sketch-guided Text-based 3D Editing](https://arxiv.org/pdf/2303.10735)
* [TextDeformer: Geometry Manipulation using Text Guidance](https://arxiv.org/pdf/2304.13348)



